#!/usr/bin/env python2
# -*- coding: utf-8 -*-

import itertools as it, operator as op, functools as ft
from plumbum import local, commands
from time import time
from collections import defaultdict
from os.path import basename, dirname, join, exists, normpath, isfile, splitext
import os, sys, re, random, tempfile, traceback, shutil, math, types

try: import mutagen, mutagenwrapper as mw
except ImportError: mutagen = mw = None

try: from unidecode import unidecode
except ImportError: unidecode = None


_size_units=list(
	reversed(list((u, 2 ** (i * 10))
	for i, u in enumerate('BKMGT'))) )

def size_human(size):
	for u, u1 in _size_units:
		if size > u1: break
	return '{:.1f}{}'.format(size / float(u1), u)

def size_human_parse(size):
	if not size or not isinstance(size, types.StringTypes): return size
	if size[-1].isdigit(): return float(size)
	for u, u1 in _size_units:
		if size[-1] == u: break
	else: raise ValueError('Unrecognized units: {} (value: {!r})'.format(size[-1], size))
	return float(size[:-1]) * u1


cleanup_ops = list() # list of callbacks to reliably run on exit
rate_a = 0.3 # ewma exponent for per-file rate values, 0 < rate_a < 1

tags_default = dict(x='x', xxx='xxx')
tags_subs = {
	r'[\\/]': '_', r'^\.+': '_', r'[\x00-\x1f]': '_', r':': '-_',
	r'<': '(', r'>': ')', r'\*': '+', r'[|!"]': '-', r'[\?\*]': '_',
	'[\'â€™]': '', r'\.+$': '_', r'\s+$': '', r'\s': '_' }

def main(argv=None):
	default_shuffle_percentage = 30.0

	import argparse
	parser = argparse.ArgumentParser(
		usage='%(prog)s [opts] src dst',
		description='Randomly pick and copy tracks from source to destination.')

	group = parser.add_argument_group('Source/destination')
	group.add_argument('src', nargs='*', help='Source path(s).')
	group.add_argument('dst', nargs='?', help='Destination path.')
	group.add_argument('-l', '--src-list', action='store_true',
		help='Treat "src" argument(s) as a list of files to copy (either newline or zero-delimeted).')
	group.add_argument('-m', '--move', action='store_true', help='Move files instead of copying.')
	group.add_argument('--any-ext', action='store_true',
		help='Disable filtering for mp3/ogg files only (by filename extension) and copy any files.')

	group = parser.add_argument_group('Filename generation')
	group.add_argument('--raw-names', action='store_true',
		help='Do not rename tracks according to --name-format.')
	group.add_argument('-f', '--name-format',
		metavar='py_format_tpl', default='{0[title]}_[{0[tracknumber]}]_--_{0[artist]}',
		help='Format to rename tracks to when copying to destination.'
			' Same syntax as for python str.format, with keys'
				' from mutagenwrapper (see docs for full list of these).'
			' Will not be used if mutagenwrapper is not available.')
	group.add_argument('--name-format-check',
		metavar='key1[,key2,...]', default='title',
		help='Comma-separated list of keys to check before'
				' renaming file according to --name-format.'
			' If any of them is empty or missing, rename will not be performed.'
			' Can be empty. Default: %(default)s')
	group.add_argument('--name-format-mappings',
		metavar='k1=v1[,v2,...][|k2=v3[v4,...]|...]',
		default=(
			'artist=albumartist,artist,TPE2'
				',TPE1,TPE2,TSOP,TXXX:Album Artist Credit,TXXX:Artist Credit,xxx|'
			'title=title,TIT2|' 'album=album,TALB,xxx|' 'tracknumber=tracknumber,TRCK,x|' ),
		help='Fallback keys to use if direct match is empty. Default: %(default)s')
	group.add_argument('--name-format-raw', action='store_true',
		help='Avoid doing any string replacements on filename (to make it more fs-friendly).')
	group.add_argument('--name-len-max',
		type=int, metavar='number', default=160,
		help='Trim name to specified length.'
			' No collision-detection afterwards. Default: %(default)s')

	group = parser.add_argument_group('Free space cleanup')
	group.add_argument('-s', '--min-df', metavar='float [ B | K | M | G | T ]',
		help='Threshold of df on dst path to stop on.'
			' Simple number (float) will be interpreted as MiB, but unit letter'
				' (B, K, M, G, T) can be specified immediately after, e.g. "2.2G" for 2.2 GiB.')
	group.add_argument('-c', '--clean-df', metavar='float [ B | K | M | G | T ]',
		help='Before copying stuff, clean up files from'
				' destination path (also see --clean-path) up to specified free-space'
				' threshold (or until theres nothing left). Files to remove are picked at random.'
			' Same value spec format as with --min-df.')
	group.add_argument('-a', '--clean-as-necessary',
		action='store_true', help='Clean up files from destination path'
			' (also see --clean-path) as necessary to copy *all* the source files.'
			' Files to remove are picked at random. Mutually exclusive with --min-df.')
	group.add_argument('-r', '--clean-path', metavar='path',
		help='Clean stuff from the specified path instead of destination.')

	group = parser.add_argument_group('Sort/shuffle options')
	group.add_argument('-o', '--ordering', action='store_true',
		help='Copy tracks in (alphanumeric) order of their full path.')
	group.add_argument('--shuffle',
		nargs='?', metavar='percentage', default=False,
		help=( 'Special operation mode, which will:'
				' (1) Lookup all paths in src, build a set of basenames for these.'
				' (2) Lookup all paths in dst, find difference with src set.'
				' (3) Copy missing files from dst to src (or staging area with -t option).'
				' (4) Remove random files in dst, leaving specified count percentage (default: {:.1f}%%).'
				' (5) Pick random files from src and staging area and upload to dst.' )\
			.format(default_shuffle_percentage))
	group.add_argument('-t', '--shuffle-staging',
		nargs='?', metavar='path', default='/var/tmp/pick_tracks.XXXXXX',
		help='Path to temporarily copy files from dst during --shuffle operation, removed afterwards.'
			' Will be generated in mktemp(1)-fashion if name contains >4 X letters in a row.')

	group = parser.add_argument_group('Debug/misc')
	group.add_argument('-i', '--ignore-errors', action='store_true',
		help='Dont abort on any errors from rsync.'
			' These can usually happen due to e.g. fs name restrictions and whatever other io errors.')
	group.add_argument('--dry-run', action='store_true', help='Dont do the actual cp/rm part.')
	group.add_argument('--debug', action='store_true', help='Verbose operation mode.')
	optz = parser.parse_args(argv if argv is not None else sys.argv[1:])

	import logging
	logging.basicConfig(level=logging.DEBUG if optz.debug else logging.INFO)
	log = logging.getLogger()

	if optz.src and not optz.dst: optz.src, optz.dst = optz.src[:-1], optz.src[-1]
	if optz.shuffle is None: optz.shuffle = True
	if optz.src and (optz.clean_as_necessary and optz.min_df):
		parser.error('Options --min-df and --clean-as-necessary do not make sense together')
	if optz.shuffle and (optz.clean_df or optz.clean_as_necessary or optz.clean_path):
		parser.error('Options --clean* and --shuffle do not make sense together')
	if not (optz.clean_df or optz.clean_as_necessary or optz.clean_path):
		if not optz.dst: parser.error('No "dst" path specified.')
		if not optz.src and not optz.shuffle:
			parser.error('At least one "src" path must be specified, unless --shuffle is used.')
	else:
		if not optz.src and not optz.shuffle and optz.clean_path: optz.clean_as_necessary = True
		if not optz.dst:
			if not optz.clean_path:
				parser.error('Either "dst" or --cleanup-path must be specified for cleanup.')
			else: optz.dst = optz.clean_path

	MiB = float(2**20)
	if not exists(optz.dst):
		local['mkdir']('-p', optz.dst)
		log.debug('Created: {}'.format(optz.dst))
	if optz.min_df:
		try: optz.min_df = float(optz.min_df) * MiB
		except ValueError: optz.min_df = size_human_parse(optz.min_df)

	optz.clean = optz.clean_df or optz.clean_as_necessary
	if optz.clean:
		if optz.clean_df:
			try: optz.clean_df = float(optz.clean_df) * MiB
			except ValueError: optz.clean_df = size_human_parse(optz.clean_df)
	if not optz.clean_path: optz.clean_path = optz.dst

	if not optz.name_format or not mw:
		if not optz.raw_names:
			log.debug( 'Auto-setting --raw-names due to missing prequesites for'
					' tag-based renaming (empty format: %r, mutagenwrapper module available: %r)',
				not optz.name_format, mw )
		optz.raw_names = True
	optz.name_format_check = filter( None,
		map(bytes.strip, optz.name_format_check.split(',')) )
	optz.name_format_mappings, specs = dict(), optz.name_format_mappings.split('|')
	for spec in specs:
		if not spec.strip(): continue
		k, vs = spec.split('=', 1)
		vs = filter(None, map(bytes.strip, vs.split(',')))
		optz.name_format_mappings[k] = vs
	if not unidecode:
		log.debug('Failed to import unidecode module, name transliteration will be disabled.')


	### Misc helpers

	def force_bytes(s):
		if isinstance(s, unicode): return s.encode('utf-8')
		return s

	def force_unicode(s, encoding='utf-8', errors='replace'):
		if isinstance(s, unicode): return s
		return s.decode(encoding, errors)

	def to_bytes(obj, **conv_kws):
		if not isinstance(obj, types.StringTypes): obj = bytes(obj)
		return force_bytes(obj)

	def free(path=optz.dst):
		df = os.statvfs(path)
		return float(df.f_bavail * df.f_bsize)

	def pop_path(path_list):
		idx = ( 0 if optz.ordering
			else random.randint(0, len(path_list) - 1) )
		path = path_list.pop(idx)
		return path

	def do_cleanup(df_goal=optz.clean_df):
		if optz.dry_run:
			log.debug('Cleanup dry-run (goal: %.0f MiB)', df_goal / MiB)
			return
		while cleanup:
			df = free(optz.clean_path)
			if df >= df_goal: break
			path = force_bytes(pop_path(cleanup))
			log.debug(
				'Removing file (df: {:.1f} / {:.1f} MiB): {!r}'\
				.format(df / MiB, df_goal / MiB, path) )
			try: os.unlink(path)
			except OSError as err:
				log.warn('Failed to remove file ({}): {}'.format(path, err))

	_track_name_subs = list(
		(re.compile(k), v) for k,v in tags_subs.viewitems() )
	def track_name(path):
		name = basename(path)
		if optz.raw_names: return name
		try: tags_raw = mw.read_tags(path)
		except:
			try: tags_raw = mutagen.File(path).tags
			except: return name
		if not tags_raw: return name

		tags = tags_default.copy()
		for k, v in tags_raw.iteritems():
			if not isinstance(v, list): v = getattr(v, 'text', None)
			if not v: continue
			if not isinstance(v, list): v = [to_bytes(v)]
			tags[to_bytes(k)] = to_bytes(v[0])

		if not tags: return name
		tags = defaultdict( bytes,
			((k, to_bytes(v).replace('/', '-')) for k, v in tags.iteritems()) )
		for k, vs in optz.name_format_mappings.viewitems():
			for v in vs:
				if tags[v]: break
			else: continue
			tags[k] = tags[v]

		if optz.name_format_check\
				and not all(list(tags.get(k) for k in optz.name_format_check)):
			return name
		name, ext = optz.name_format.format(tags), splitext(name)[-1]
		if optz.name_len_max > 0: name = name[:optz.name_len_max]

		if not optz.name_format_raw:
			for sub_re, sub in _track_name_subs: name = sub_re.sub(sub, name)

		return name + ext


	### Build a list of files we're allowed to remove, if any cleanup is requested
	if optz.clean or optz.shuffle:
		cleanup = list()
		if not exists(optz.clean_path):
			log.info('Cleanup path does not exists: {}'.format(optz.clean_path))
		else:
			if optz.clean_df:
				log.debug(
					'Starting cleanup (up to: {:.1f} MiB) of the path: {!r}'\
					.format(optz.clean_df / MiB, optz.clean_path) )
			code, cleanup, err = local['find'].run([optz.clean_path, '-type', 'f'])
			cleanup = cleanup.splitlines()
			if optz.clean_df: do_cleanup() # do pre-cleanup, if enabled

	### Build file list
	log.debug('Building list of files in source paths')
	if optz.src:
		if optz.src_list:
			src_lists, src_files = list(), list()
			for src in optz.src:
				with open(src) as src: src_lists.append(src.read())
			for path in '\0'.join(src_lists).replace('\n', '\0').split('\0'):
				path = path.rstrip('\r')
				if not path: continue
				if not isfile(path):
					log.warn('Skipping path %r: not a file', path)
					continue
				src_files.append(path)
		else:
			src_files = ['-type', 'f']
			if not optz.any_ext: src_files += '( -name *.mp3 -o -name *.ogg )'.split()
			code, src_files, err = local['find'].run(list(optz.src) + src_files)
			if code or err:
				sys.stderr.write(err)
				raise RuntimeError('find (paths: {!r}) exited with non-zero status'.format(optz.src))
			src_files = src_files.splitlines()
	else: src_files = list()
	src_files.sort()
	log.debug(' - found {} files'.format(len(src_files)))

	### Shuffle operation
	if optz.shuffle:
		# Drop some percentage of files that will be left alone
		optz.shuffle = default_shuffle_percentage\
			if optz.shuffle is True else float(optz.shuffle)
		for n in xrange(int(math.ceil(len(cleanup) * (optz.shuffle / 100.0)))): pop_path(cleanup)
		# Compare src to cleanup
		src_basenames = set(it.imap(basename, src_files))
		cleanup_move = set(path for path in cleanup if basename(path) not in src_basenames)
		if cleanup_move:
			if 'XXXX' in optz.shuffle_staging:
				prefix, suffix = optz.shuffle_staging.split('XXXX', 1)
				prefix, suffix = prefix.rsplit(os.sep, 1), suffix.lstrip('X')
				prefix_path, prefix = ('.', prefix) if len(prefix) == 1 else prefix
				optz.shuffle_staging = tempfile.mkdtemp(suffix, prefix, prefix_path)
				cleanup_ops.append( lambda:\
					shutil.rmtree(optz.shuffle_staging, ignore_errors=True) )
				log.debug('Using tmp shuffle-path: {}'.format(optz.shuffle_staging))
			# move non-src-matching stuff to staging
			rsync_opts = [ '--inplace', '-r', '--remove-source-files',
				'--size-only', '--include-from', '-', '--exclude', '*',
				join(normpath(optz.dst), '.'), optz.shuffle_staging ]
			if optz.debug: rsync_opts.append('-P')
			if optz.dry_run: rsync_opts.append('--dry-run')
			((local['rsync'] << '\n'.join(it.imap(basename, cleanup_move))) > sys.stdout)(*rsync_opts)
			local['sync']() # so that fat will purge these entries from old places reliably
			src_files.extend(join(optz.shuffle_staging, basename(p)) for p in cleanup_move)
			src_files.sort()
			# cleanup_move paths should be removed by rsync's --remove-source-files by now
			cleanup = list(p for p in cleanup if p not in cleanup_move)
		# remove src-matching stuff
		if not optz.dry_run:
			for path in cleanup: os.unlink(path)

	# Perform --clean-as-necessary cleanup to specified --min-df, if no sources specified
	elif optz.clean_as_necessary and optz.min_df and not src_files: do_cleanup(optz.min_df)

	### Stats
	df0, ts0 = free(), time()
	df_last, ts_last, rate = df0, ts0, None
	stats = lambda: 'Done: {:.1f} MiB, rate: {:.2f} MiB/s'.format((df0 - df) / MiB, rate / MiB)

	### Copy files
	df, ts, rate = free(), time(), 0
	while src_files:
		# ewma is used here reflect changing speeds
		#  (due to cached writes and/or other activity) faster.
		df, ts = free(), time()
		rate_n = (df_last - df) / ((ts - ts_last) or 0.001)
		rate = (rate_a * rate_n + (1 - rate_a) * rate)\
			if rate is not None else rate_n
		df_last, ts_last = df, ts

		if optz.min_df:
			if df < optz.min_df: break
			to_fill = df - optz.min_df
			time_left = int(to_fill / rate) if rate != 0 else 0
			time_left = '{}m {}s'.format(time_left / 60, time_left % 60)
			log.debug(
				' - space left to fill: {:.1f} MiB, rate: {:.2f} MiB/s, left: {}'\
				.format(to_fill / MiB, rate / MiB, time_left) )

		path = force_bytes(pop_path(src_files))
		log.debug('Copying: {!r}'.format(path))

		path_dst = force_unicode(track_name(path))
		if unidecode: path_dst = unidecode(path_dst)
		path_dst = join(optz.dst, path_dst.encode('utf-8', 'backslashreplace'))
		try:
			if optz.clean_as_necessary: # free space for a file, if requested
				df_path = (os.stat(path).st_size + 1*2**20) * 1.2 # for any possible fs overhead
				if df < df_path: do_cleanup(df_path)
			if not optz.dry_run:
				rsync_opts = ['--inplace', '--size-only', '--append-verify']
				if optz.move: rsync_opts += ['--remove-source-files']
				rsync_opts.extend([path, path_dst])
				try: local['rsync'](*rsync_opts)
				except commands.processes.ProcessExecutionError as err:
					if not optz.ignore_errors: raise
					log.warn('File transfer error: %s', err)
		except KeyboardInterrupt:
			try: os.unlink(path_dst)
			except OSError: pass
			log.info('Aborted. {}'.format(stats()))
			sys.exit()

	### Success
	rate = (df0 - free()) / (time() - ts0) # median rate
	log.info(stats())


if __name__ == '__main__':
	try: err = main()
	finally:
		for func in cleanup_ops:
			try: func()
			except: traceback.print_exc()
	sys.exit(err)
