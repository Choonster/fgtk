#!/usr/bin/env python3

from construct import (
	Struct, Byte, Bytes, Int8ul, Int16ul, Int32ul, Enum, Array,
	Padding, Embedded, Pass, BitStruct, Flag, Const, ExprAdapter )
from construct.core import StreamError

import itertools as it, operator as op, functools as ft
from io import BytesIO
import os, sys, random, collections


Fat32Header = Struct(
	'jumpInstruction' / Bytes(3), # Boot Sector start
	'creatingSystemId' / Bytes(8),
	'sectorSize' / Int16ul, # FAT32 Extended BIOS Parameter Block start
	'sectorsPerCluster' / Byte,
	'reservedSectorCount' / Int16ul,
	'fatCount' / Byte,
	'rootdirEntryCount' / Int16ul,
	'sectorCount_small' / Int16ul,
	'mediaId' / Byte,
	'sectorsPerFat' / Int16ul, # 0 for FAT32, BIOS Parameter Block end
	'sectorsPerTrack' / Int16ul,
	'sideCount' / Int16ul,
	'hiddenSectorCount' / Int32ul,
	'sectorCount_large' / Int32ul, # DOS 3.31 BPB end
	'sectorsPerFat_large' / Int32ul,
	'driveFlags' / Bytes(2),
	'Version' / Bytes(2),
	'clusterOfRoot' / Int32ul,
	'fsInfoSectorNo' / Int16ul,
	'bsCopySectorNo' / Int16ul,
	'Reserved' / Bytes(12),
	'physicalDriveNumber' / Byte,
	'currentHead' / Byte,
	'extendedBootSignature' / Byte,
	'volumeId' / Bytes(4),
	'volumeLabel' / Bytes(11),
	'fsType' / Const(b'FAT32   '), # FAT32 Extended BIOS Parameter Block end
	'bootCode' / Bytes(419),
	'physicalDriveNumber_old' / Byte,
	'bootSectorSignature' / Const(b'\x55\xaa') )

BootSector = Struct(
	Embedded(Fat32Header),
	Padding(lambda ctx: ctx.sectorSize - Fat32Header.sizeof()) )

FatEntry = Enum(
	ExprAdapter(
		'fats' / Int32ul,
		encoder=lambda obj,ctx: obj,
		decoder=lambda obj,ctx: obj & 0x0fffffff ), # upper nibble is reserved
	free=0x0000000,
	reserved=0x0000001,
	reserved_nb=0xffffff6,
	bad=0xffffff7,
	_default_=Pass )


ts_hms = ExprAdapter(
	Int16ul,
	encoder=lambda ts,ctx: (ts[0] << 11) + (ts[1] << 5) + ts[2] // 2,
	decoder=lambda n,ctx: (n >> 11, (n >> 5) & (2**6 - 1), (n & (2**5 - 1)) * 2) )

ts_ymd = ExprAdapter(
		Int16ul,
		encoder=lambda ts,ctx: ((ts[0] - 1980) << 9) + (ts[1] << 5) + ts[2],
		decoder=lambda n,ctx: (1980 + (n >> 9), (n >> 5) & (2**4 - 1), n & (2**5 - 1)) )

# Should have Switch in it for LFN, but not sure how to integrate it
DirEntry = Struct(
	'name' / Bytes(8),
	'extension' / Bytes(3),
	'attributes' / BitStruct(
		'unused' / Flag,
		'device' / Flag,
		'archive' / Flag,
		'subDirectory' / Flag,
		'volumeLabel' / Flag,
		'system' / Flag,
		'hidden' / Flag,
		'readonly' / Flag ),
	'reserved_flags' / Byte,
	'undelete_char_or_ctime_ms' / Byte,
	'ctime_hms' / ts_hms,
	'ctime_ymd' / ts_ymd,
	'atime_ymd' / ts_ymd,
	'firstCluster_high' / Int16ul,
	'mtime_hms' / ts_hms,
	'mtime_ymd' / ts_ymd,
	'firstCluster_low' / Int16ul,
	'fileSize' / Int32ul )

LFNEntry = Struct(
	'seq' / Int8ul,
	'name1' / Bytes(10),
	'attributes' / BitStruct( # always 0xfd for LFN
		'unused' / Flag,
		'device' / Flag,
		'archive' / Flag,
		'subDirectory' / Flag,
		'volumeLabel' / Flag,
		'system' / Flag,
		'hidden' / Flag,
		'readonly' / Flag ),
	'type' / Byte, # always 0x00
	'checksum' / Int8ul,
	'name2' / Bytes(12),
	'first_cluster' / Bytes(2), # always 0x0000
	'name3' / Bytes(4) )


def PreDataRegion(fsinfo=False, fats=True):
	entries = [Embedded(BootSector)]
	reserved_padding = Padding(lambda ctx: (ctx.reservedSectorCount - 1) * ctx.sectorSize)
	if fsinfo:
		entries.append(Padding(lambda ctx: (ctx.fsInfoSectorNo - 1) * ctx.sectorSize))
		# https://en.wikipedia.org/wiki/File_Allocation_Table#FS_Information_Sector
		# entries.append(Embedded(FSInfoSector('fsInfoSector')))
		reserved_padding = Padding(
			lambda ctx: (ctx.reservedSectorCount - ctx.fsInfoSectorNo - 1) * ctx.sectorSize )
		raise NotImplementedError
	if fats:
		entries.append(reserved_padding)
		entries.append('fats' / Array( lambda ctx: ctx.fatCount,
			Array(lambda ctx: ctx.sectorsPerFat_large * ctx.sectorSize // FatEntry.sizeof(), FatEntry) ))
	return Struct(*entries)


class File:

	name_long = None

	def __init__(self, de, fs):
		self.de, self.fs = de, fs

	def parse_des(self, de_list, fs):
		# LFN logic should be in DirEntry, but not sure how to put it there
		lfn_csum, lfn_cache = None, list()
		is_lfn = lambda e, attrs=op.attrgetter(
			'system', 'hidden', 'readonly' ): all(attrs(e.attributes))

		for entry in de_list:
			entry_id = 'DirEntry[{}]'.format(entry.clidx)

			if entry.name[0] == 0xe5: continue # deleted
			if entry.name[0] == 0x2e: # dot-entries
				entry.lfns, entry.name_long = list(), entry.name.decode()
				assert not entry.name_long.strip('. '), repr(entry.name_long)
				yield DotEntry(entry, fs)
				continue
			assert entry.name[0] != 0, repr(entry.name)

			stream = entry.pop('_chain_stream') # if only to free the ref
			log.debug('DirEnty[%s] at %s', entry.clidx, entry.slice_map_offset)
			if is_lfn(entry): # has to be re-parsed as LFN here
				if not lfn_cache: log.debug('Detected long-name %s', entry_id)
				stream.seek(entry.slice_map_offset)
				entry_lfn = LFNEntry.parse_stream(stream)
				entry_lfn.seq_num = entry_lfn.seq
				entry_lfn.slice_map, entry_lfn.slice_map_offset = entry.slice_map, entry.slice_map_offset
				if not lfn_cache:
					if not entry_lfn.seq_num & 0x40:
						log.error( 'Unset bit-6 of seq in last'
							' (logical, first physical) LFN entry:\n%s', entry_lfn )
						raise ValueError(entry_lfn.seq_num)
					entry_lfn.seq_num ^= 0x40
					lfn_csum = entry_lfn.checksum
				else:
					assert lfn_csum == entry_lfn.checksum
				lfn_cache.append(entry_lfn)
				log.debug('  LFN entry seq: %s (hex: %s)', entry_lfn.seq_num, hex(entry_lfn.seq_num))
				continue

			elif lfn_cache:
				lfn_name = it.chain.from_iterable(
					[lfn.name1, lfn.name2, lfn.name3]
					for lfn in sorted(lfn_cache, key=op.attrgetter('seq_num')) )
				entry.name_long = b''.join(lfn_name).decode('utf-16').split('\0')[0]
				lfn_cache, entry.lfns = list(), lfn_cache
				csum, name = 0, iter(entry.name + b'\0' * (len(entry.name) - 8) + entry.extension)
				for n in range(11):
					c = next(name)
					csum = (((csum & 1) << 7) + (csum >> 1) + c) & 0xff
				assert csum == lfn_csum, [csum, lfn_csum]

			else:
				name = entry.name
				if name[0] == 0x05: name = b'\xe5' + name[1:] # 0x05 - Initial character is actually 0xE5
				name, ext = name.decode().strip(), entry.extension.decode().strip()
				if ext: name = '{name}.{ext}'
				entry.lfns, entry.name_long = list(), name

			is_dir = entry.attributes.subDirectory
			log.debug('Parsing %s: %r (%s)', entry_id, entry.name_long, 'dir' if is_dir else 'file')
			yield (Directory if is_dir else File)(entry, fs)

	def copy(self, dst_stream):
		self.fs.copy_chain(self.firstCluster, dst_stream)

	def get_chain(self):
		return self.fs.get_chain(self.firstCluster)

	def get_slice_map(self):
		return list(map(self.fs.get_slice, self.get_chain()))

	@property
	def firstCluster(self):
		return (self.de.firstCluster_high << 16) + self.de.firstCluster_low

	def __str__(self): return f'[{self.firstCluster:7d}] {self.de.name_long}'
	def __repr__(self):
		return ( f'<{self.__class__.__name__}'
			f' {self.firstCluster}:[{self.de.name_long!r}]>' )


class DotEntry(File):

	def __str__(self): return f'[{" "*7}] {self.de.name_long}'
	def __repr__(self): return f'<{self.__class__.__name__} [{self.de.name_long.strip()}]>'


class Directory(File):

	def __init__(self, de, fs):
		super(Directory, self).__init__(de, fs)
		self.children = list(self.parse_des(self.fs.get_des(self.firstCluster), fs))

	struct_tuple = collections.namedtuple('StructTuple', 'struct data')
	def iter_struct_tuples( self,
			sort_func=None, group_dirs=None, group_dirs_sort_func=None ):
		assert group_dirs in [None, False, 'first', 'last'], group_dirs
		if not sort_func: sort_func = lambda des: None
		if not group_dirs_sort_func: group_dirs_sort_func = sort_func

		parts = collections.namedtuple( 'Parts',
			'dots dirs_first whatever dirs_last' )(list(), list(), list(), list())
		for obj in self.children:
			if group_dirs and isinstance(obj, Directory):
				if group_dirs == 'first': dst = parts.dirs_first
				elif group_dirs == 'last': dst = parts.dirs_last
				else: raise ValueError(group_dirs)
			elif isinstance(obj, DotEntry): dst = parts.dots
			else: dst = parts.whatever
			dst.append(obj)

		for k, des in parts._asdict().items():
			if k == 'dots': continue # dotentries
			res = (sort_func if k == 'whatever' else group_dirs_sort_func)(des)
			if res is None: continue # assuming it's an in-place list sorter
			des[:] = res

		log.debug('Resulting directory order:')
		for obj in it.chain(*parts):
			log.debug('  %s', obj)
			for lfn in obj.de.lfns: yield self.struct_tuple(LFNEntry, lfn)
			yield self.struct_tuple(DirEntry, obj.de)

	def __getitem__(self, name):
		for obj in self.children:
			if obj.de.name_long == name: return obj
		raise KeyError(name)

	def __iter__(self):
		return iter(self.children)

	def __str__(self): return f'[{self.firstCluster:7d}] {self.de.name_long}/'


class FatFs(Directory):

	# Concepts and shorthands:
	#  chain - list of indexes of linked clusters
	#  slice - byte range (start + length) in file for cluster
	#  slice map - list of slices (clusters mapped to file) for some object
	#  de(s) - DirEntry struct(s)

	def __init__(self, stream):
		self.stream = stream
		self.pdr = PreDataRegion().parse_stream(stream)
		super(FatFs, self).__init__(None, self)

	def get_next_cluster(self, clidx):
		ress = set([fat[clidx] for fat in self.pdr.fats])
		if len(ress) == 1: return ress.pop()
		log.error('Inconsistency between FATs: %s points to', clidx)
		for i, fat in enumerate(self.pdr.fats):
			log.error('    %s according to fat #%s' , fat[clidx], i)
		res = ress.pop()
		log.error('  assuming %s', res)
		return res

	def get_chain(self, clidx):
		res, clidx_start = [], clidx
		while clidx < 0xffffff8: # last cluster is 0xffffff8-0xfffffff
			assert isinstance(clidx, int), clidx
			assert 2 <= clidx <= 0xfffffef, 'Non-data cluster: {}'.format(hex(clidx))
			res.append(clidx)
			clidx = self.get_next_cluster(clidx)
			assert clidx not in res, [clidx, res]
		log.debug('Linked clusters from %s: %s', clidx_start, res)
		return res

	def get_slice(self, clidx):
		startSector = (
			self.pdr.reservedSectorCount
				+ self.pdr.fatCount * self.pdr.sectorsPerFat_large
				+ (clidx-2) * self.pdr.sectorsPerCluster )
		start = startSector * self.pdr.sectorSize
		length = self.pdr.sectorSize * self.pdr.sectorsPerCluster
		# log.debug(
		# 	'Cluster slice (clidx: %s): %s (hex: %s, len: %s)',
		# 	clidx, start, hex(start), length )
		return start, length

	def copy_slice(self, dst_stream, start, length):
		self.stream.seek(start)
		while length > 0:
			read = self.stream.read(length)
			if not len(read):
				log.error('Failed to read %s bytes at %s', length, self.stream.tell())
				raise EOFError()
			length -= len(read)
			dst_stream.write(read)

	def copy_chain(self, clidx, stream):
		clidx_list, slice_map = self.get_chain(clidx), list()
		for clidx in clidx_list:
			start, length = self.get_slice(clidx)
			self.copy_slice(stream, start, length)
			slice_map.append((start, length))
		return slice_map

	def get_des(self, clidx):
		try:
			for de in self._get_des(clidx): yield de
		except IOError:
			log.exception('Failed to read directory entries at %s', clidx)

	def _get_des(self, clidx):
		with BytesIO() as mem:
			slice_map = self.copy_chain(clidx, mem)
			mem.seek(0)
			while True:
				if not mem.read(1): break
				mem.seek(-1, os.SEEK_CUR)
				pos = mem.tell()
				obj = DirEntry.parse_stream(mem)
				if obj.name[0] == 0: break # sentinel entry
				obj.clidx, obj._chain_stream = clidx, mem
				obj.slice_map, obj.slice_map_offset = slice_map, pos
				yield obj

	def write_struct(self, struct, data, slice_map=None, slice_map_offset=None, dry_run=False):
		if slice_map is None: slice_map = data.slice_map
		if slice_map_offset is None: slice_map_offset = data.slice_map_offset

		pos, sm_iter = slice_map_offset, iter(slice_map)
		for start, length in sm_iter:
			if pos < length:
				start, length = start + pos, length - pos
				break
			pos -= length
		else: raise EOFError(slice_map, slice_map_offset, pos)

		with BytesIO() as buff:
			struct.build_stream(data, buff)
			buff_len = buff.tell()
			buff.seek(0)

			writes = list()
			while buff_len > 0:
				write_len = min(buff_len, length)
				writes.append((start, write_len))
				buff_len -= write_len
				if buff_len <= 0: break
				try: start, length = next(sm_iter)
				except StopIteration:
					raise EOFError(slice_map, slice_map_offset, buff_len)
			log.debug( 'Mapped %s write-slices for %s'
				' %s\nWrites (start, len): %s', len(writes), struct, data, writes )

			if not dry_run:
				for start, length in writes:
					self.stream.seek(start)
					self.stream.write(buff.read(length))

	@property
	def firstCluster(self): return self.pdr.clusterOfRoot

	name_tpl = '[{1.pdr.clusterOfRoot}] /'


def run_proc(cmd, sudo=False, out=True, **kws):
	import subprocess
	if isinstance(cmd, str): cmd = cmd.split()
	else: cmd = list(map(str, cmd))
	if sudo: cmd = ['sudo', '-n'] + cmd
	log.debug('Command: %s', ' '.join(cmd))
	if out is ...:
		kws.update(
			stdout=subprocess.DEVNULL,
			stderr=subprocess.DEVNULL )
	elif out: kws.update(check=True, stdout=subprocess.PIPE)
	res = subprocess.run(cmd, **kws)
	return res.stdout.decode() if out is True else res

def op_resolve_mp(vfs_path, error_func):
	import json, pathlib as pl
	path = pl.Path(vfs_path).resolve()
	lsblk = json.loads(run_proc('lsblk --json --paths'.split()))
	mp_list, lsblk = list(), collections.deque(lsblk['blockdevices'])
	while lsblk:
		dev = lsblk.popleft()
		lsblk.extend(dev.get('children') or list())
		mp = dev.get('mountpoint')
		if not mp: continue
		try: p = path.relative_to(mp)
		except ValueError: pass
		else: mp_list.append((dev['name'], str(p), str(mp)))
	dev, path, mp = sorted(mp_list, key=lambda dev: len(dev[2]))[-1]
	if mp == '/': error_func(f'Failed to resolve path to non-root mountpoint: {path}')
	return dev, path, mp

def op_navigate(root, path):
	path, slugs = root, os.path.normpath(path).lstrip(os.sep).split(os.sep)
	for k in filter(None, slugs): path = path[k]
	return path

def op_recurse(*paths):
	paths, path_queue = list(), collections.deque(paths)
	while path_queue:
		p = path_queue.popleft()
		if not isinstance(p, Directory): continue
		paths.append(p)
		path_queue.extend(p.children)
	return paths


def op_list(path, recursive=False, indent=0, print_line=None):
	if print_line is None:
		def print_line(line='', pad_in=False, pad_out=False):
			if pad_in and not print_line.pad_state: print()
			if line: print(line)
			if pad_out: print()
			print_line.pad_state = pad_out
		print_line.pad_state = True
	for p in path:
		if isinstance(p, DotEntry): continue
		recurse = recursive and isinstance(p, Directory)
		print_line(indent*' ' + str(p), pad_in=recurse)
		if recurse:
			op_list(p, recursive=True, indent=indent+3, print_line=print_line)
			print_line(pad_out=True)

def op_rename(path, tpl, dry_run=False):
	name = tpl.decode('utf-8').format(name=path.de.name_long)
	log.debug('Renaming %s -> %r', path, name)
	with BytesIO((name + '\0').encode('utf-16')) as name_raw:
		name_raw.seek(0)
		assert name_raw.read(2) == b'\xff\xfe' # BOM
		for lfn in path.de.lfns:
			for field in LFNEntry.subcons:
				if field.name in ['name1', 'name2', 'name3']:
					field_len = field.sizeof()
					data = name_raw.read(field_len)
					lfn[field.name] = data + b'\xff' * (field_len - len(data))
			fs.write_struct(LFNEntry, lfn, dry_run=dry_run)

def op_reorder(path, src, dry_run=False, **reorder_kws):
	path_sts_orig = list(path.iter_struct_tuples())
	path_sts_sorted = list(path.iter_struct_tuples(**reorder_kws))

	path_sts_hashed = [
		tuple(id(st.data) for st in sts)
		for sts in [path_sts_orig, path_sts_sorted] ]
	if path_sts_hashed[0] == path_sts_hashed[1]:
		log.debug('Reorder for path was not needed, skipping: %r', path)
		return

	with BytesIO() as mem:
		# Dump all path_structs to mem
		for struct, data in path_sts_sorted:
			# log.debug('Writing-out struct (%sB):\n%s', struct.sizeof(), data)
			try: struct.build_stream(data, mem)
			except StreamError:
				log.error('Failed to serialize construct: %s', data)
				raise
		slice_map = path.get_slice_map()
		len_structs, len_clusters = mem.tell(), sum(map(op.itemgetter(1), slice_map))
		assert len_structs <= len_clusters, [len_structs, len_clusters]

		# Actual write operation
		mem.seek(0)
		for start, length in slice_map:
			src.seek(start)
			chunk = mem.read(length)
			log.info(
				'Writing %sB to offset: %s (hex: %s, len_left: %s)',
				len(chunk), start, hex(start), length )
			if not dry_run: src.write(chunk)
			length -= len(chunk)
			if length > 0:
				chunk = b'\0'*length
				log.info('Padding remaining %sB with zeroes', len(chunk))
				if not dry_run: src.write(chunk)
		assert mem.tell() == len_structs, [mem.tell(), len_structs]


def main(args=None):
	import argparse, textwrap

	dedent = lambda text: (textwrap.dedent(text).strip('\n') + '\n').replace('\t', '  ')
	class SmartHelpFormatter(argparse.HelpFormatter):
		def __init__(self, *args, **kws):
			return super().__init__(*args, **kws, width=100)
		def _fill_text(self, text, width, indent):
			if '\n' not in text: return super()._fill_text(text, width, indent)
			return ''.join(indent + line for line in text.splitlines(keepends=True))
		def _split_lines(self, text, width):
			return super()._split_lines(text, width)\
				if '\n' not in text else dedent(text).splitlines()

	parser = argparse.ArgumentParser(
		formatter_class=SmartHelpFormatter,
		description=dedent('''
			Raw FAT32 manipulation tool.
			Simply lists files in specified directory by default.
			Use options like -s/--shuffle and --rename to specify other actions.'''),
		epilog=dedent('''
			Usage examples:

				List files in order they are stored (with -r/--recursive to do it recursively):
					% vfat_shuffler /dev/sdd1 /music/misc
					% vfat_shuffler -lr /dev/sdd1 /music

				Order stuff alphabetically, grouping dirs before files (default for -g/--group-dirs):
					% vfat_shuffler -o /dev/sdd1 /music/misc
					% vfat_shuffler -or /dev/sdd1 /
					% vfat_shuffler -o --case-insensitive /mnt/player/music/misc
					% vfat_shuffler -or --sudo --umount /mnt/player/music

				Shuffle files (randomize order):
					% vfat_shuffler -srx /mnt/player/music
		'''))

	group = parser.add_argument_group('Device and path')
	group.add_argument('dev_or_vfs_path',
		help='''
			Path to FAT32 device or mountpoint path.
			If only path inside mountpoint is specified,
			  device-name/path will be resolved using "lsblk" tool (util-linux) from it,
			  device unmounted, acted upon, and remounted (default opts) to same mountpoint.''')
	group.add_argument('path', nargs='?',
		help='File/directory to operate on. Must start from /, example: /some/my/dir')

	group = parser.add_argument_group('Operations')
	group.add_argument('-l', '--list', action='store_true',
		help='''
			List path without shuffling anything, in entry-order.
			Default action, if no other options are specified.''')
	group.add_argument('-s', '--shuffle', action='store_true',
		help='''
			Shuffle entries in specified directory.'
			This reads all direntries there and writes them back in randomized order.
			Intended for stupid devices (e.g. mp3 players) which rely on that.''')
	group.add_argument('-o', '--order', action='store_true',
		help='''
			Alpha-sort entries in specified directory.
			Same idea as -s/--shuffle, but does the opposite ordering-wise.''')
	group.add_argument('--rename', metavar='template',
		help='''
			Rename specified node (file/dir) according to the template.
			Only changes utf-16 name in LFNs, as that is all modern OSes seem to care about.
			Template is for python str.format. Example: {name}.bak''')

	group = parser.add_argument_group('Operation tweaks/options')
	group.add_argument('-r', '--recursive', action='store_true',
		help='Operate on all subdirectories recursively.')
	group.add_argument('-c', '--case-insensitive', action='store_true',
		help='Use case-insensitive ordering for'
			' files/dirs with -o/--order and -g/--group-dirs options.')
	group.add_argument('-g', '--group-dirs',
		default='first', choices=['no', 'first', 'last'], metavar='type',
		help='''
			Group and alpha-sort directories at the beginning/end of the file entries.
			Possible values: first (default), last, no.
			Only used with -s/--shuffle and -o/--order operations.''')
	group.add_argument('--rename-inside', action='store_true',
		help='''
			Rename all entries inside specified directory instead of directory itself.
			When -r/--recursive is also specified, only renames files inside directories.
			Used with --rename only.''')
	group.add_argument('-x', '--sudo', action='store_true',
		help='''
			Use sudo for mount/umount commands
				when vfs path is specified instead of device+path.''')
	group.add_argument('-u', '--umount', action='store_true',
		help='When operating on a mounted path, do not remount it back.')

	group = parser.add_argument_group('Debug/output options')
	group.add_argument('-n', '--dry-run',
		action='store_true', help='Dont write the data out, only print what goes where.')
	group.add_argument('-v', '--verbose', action='store_true', help='Verbose operation mode.')
	group.add_argument('-d', '--debug', action='store_true', help='Even more verbose operation.')

	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	if not (opts.shuffle or opts.order or opts.rename): opts.list = True
	if sum(map(bool, [opts.shuffle, opts.order, opts.rename, opts.list])) != 1:
		parser.error('Only one action can be specified at the same time.')

	if opts.shuffle or opts.order:
		group_dirs = None if opts.group_dirs == 'no' else opts.group_dirs
		alphasort_func = op.attrgetter('de.name_long')
		if opts.case_insensitive:
			alphasort_func = lambda e,_f=alphasort_func: _f(e).lower()
		alphasort_func = ft.partial(sorted, key=alphasort_func)
		if opts.shuffle: sort_func = random.shuffle
		elif opts.order: sort_func = alphasort_func
		sort_opts = dict( sort_func=sort_func,
			group_dirs=group_dirs, group_dirs_sort_func=alphasort_func )

	global log
	import logging
	if opts.debug: log = logging.DEBUG
	elif opts.verbose: log = logging.INFO
	else: log = logging.WARNING
	logging.basicConfig(level=log)
	log = logging.getLogger()

	dev, path, mp = opts.dev_or_vfs_path, opts.path, None
	try:
		if not path:
			dev, path, mount = op_resolve_mp(dev, parser.error)
			os.chdir('/') # umount might fail otherwise
			run_proc(['umount', mount], sudo=opts.sudo)
			mp = mount
		elif not path.startswith(os.sep):
			parser.error( 'Path argument must begin with'
				' slash (for typo-safety reasons): {!r}'.format(path) )

		src_mode = 'rb' if not opts.dry_run and opts.list else 'rb+'
		with open(dev, src_mode) as src:
			fs = FatFs(src)
			paths = [op_navigate(fs, path)]

			if opts.list: return op_list(paths[0], recursive=opts.recursive)
			if opts.recursive: paths = op_recurse(*paths)

			for path in paths:
				if opts.rename:
					if not opts.rename_inside: op_rename(path, opts.rename)
					else:
						for entry in path:
							op_rename(entry, opts.rename, dry_run=opts.dry_run)
				elif opts.shuffle or opts.order:
					op_reorder(path, src, dry_run=opts.dry_run, **sort_opts)

	finally:
		if mp and not opts.umount:
			res = run_proc(['mount', mp], sudo=opts.sudo, out=...) # fstab check
			if res.returncode: res = run_proc(['mount', dev, mp], sudo=opts.sudo, out=...)
			if res.returncode: res.check_returncode()

if __name__ == '__main__': sys.exit(main())
