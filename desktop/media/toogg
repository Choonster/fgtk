#!/usr/bin/env python3

import itertools as it, operator as op, functools as ft
from collections import OrderedDict, namedtuple
from asyncio import subprocess
import math, datetime as dt
import os, sys, re, logging, pathlib
import contextlib, asyncio, signal, json, tempfile, shutil


class LogMessage:
	def __init__(self, fmt, a, k): self.fmt, self.a, self.k = fmt, a, k
	def __str__(self): return self.fmt.format(*self.a, **self.k) if self.a or self.k else self.fmt

class LogStyleAdapter(logging.LoggerAdapter):
	def __init__(self, logger, extra=None):
		super(LogStyleAdapter, self).__init__(logger, extra or {})
	def log(self, level, msg, *args, **kws):
		if not self.isEnabledFor(level): return
		log_kws = {} if 'exc_info' not in kws else dict(exc_info=kws.pop('exc_info'))
		msg, kws = self.process(msg, kws)
		self.logger._log(level, LogMessage(msg, args, kws), (), log_kws)

get_logger = lambda name: LogStyleAdapter(logging.getLogger(name))

err_with_type = lambda err: (err.__class__.__name__, err)

def naturaltime_diff( ts, ts0=None, ext=None,
		_units=dict( h=3600, m=60, s=1,
			y=365.25*86400, mo=30.5*86400, w=7*86400, d=1*86400 ) ):
	res, s = list(), abs( (ts - (ts0 or dt.datetime.now()))
		if not isinstance(ts, (dt.timedelta, int, float)) else ts )
	if isinstance(s, dt.timedelta): s = delta.total_seconds()
	for unit, unit_s in sorted(_units.items(), key=op.itemgetter(1), reverse=True):
		val = math.floor(s / float(unit_s))
		if not val: continue
		res.append('{:.0f}{}'.format(val, unit))
		if len(res) >= 2: break
		s -= val * unit_s
	if not res: return 'now'
	else:
		if ext: res.append(ext)
		return ' '.join(res)

class Path(pathlib.PosixPath):
	'PosixPath with a fix for resolving to "//stuff" nonsense.'
	def resolve(self, strict=False):
		p = super().resolve(strict=strict)
		return Path('/' + str(p).strip('/'))



class FFProc:

	proc = finished = None
	stream_reader_limit = 32 * 2**10
	prefix, crop_mark = '', '... ¯\_(ツ)_/¯'

	def __init__( self, loop, src, cmd,
			stream_len=None, progress_func=None, prefix=None, limit=None, **kws ):
		self.loop, self.src, self.cmd, self.kws = loop, src, cmd, kws
		self.progress_func, self.stream_len = progress_func, stream_len
		self.term_width = shutil.get_terminal_size()[0] - 2
		if prefix: self.prefix = prefix
		self.line_max_len = self.kws['limit'] = limit or self.stream_reader_limit
		self.cmd_repr = ' '.join((v if len(v.split()) == 1 else repr(v)) for v in cmd)

	async def __aenter__(self):
		await self.run(wait=False)
		return self

	async def __aexit__(self, *err):
		if self.finished and not self.finished.done():
			self.finished.cancel()
			with contextlib.suppress(asyncio.CancelledError): await self.finished


	async def run(self, wait=True):
		assert not self.proc
		log.debug('[{!r}] running: {}', self.src, self.cmd_repr)
		if self.progress_func: self.kws['stdout'] = subprocess.PIPE
		self.proc = await asyncio.create_subprocess_exec(*self.cmd, **self.kws)
		for k in 'stdin', 'stdout', 'stderr': setattr(self, k, getattr(self.proc, k))
		self.finished = self.loop.create_task(self.wait())
		if wait: await self.finished
		return self

	async def wait(self):
		progress_task = None
		if self.progress_func and self.proc.stdout:
			progress_task = self.loop.create_task(self.print_progress())
		try:
			await self.proc.wait()
			if progress_task: await progress_task
			if self.proc.returncode != 0:
				cmd_repr = '' if not self.cmd_repr else f': {self.cmd_repr}'
				raise AudioConvError(
					f'Command for src {self.src!r} exited with'
						f' non-zero status ({self.proc.returncode}){cmd_repr}' )
		finally:
			if progress_task and not progress_task.done():
				progress_task.cancel()
				with contextlib.suppress(asyncio.CancelledError): await progress_task


	async def readline(self, stream=None, sep=b'\n',
			decode_enc='utf-8', decode_err='replace', crop_to=8 * 2**10, crop_mark=None):
		'''Similar to StreamReader.readline, but also:
				- Decodes all lines (with `decode_enc` and `decode_err` opts).
				- Lines that are longer than `crop_to` (after decoding)
					are cropped to that limit and `crop_mark` is appended.
				- StreamReader `limit` is not an issue -
					line tails above that are cropped-out and discarded.'''
		if not stream: stream = self.stdout
		elif isinstance(stream, str): stream = getattr(self, stream)
		assert crop_to <= self.line_max_len
		crop_mark = crop_mark or self.crop_mark

		try: line = await stream.readuntil(sep)
		except asyncio.IncompleteReadError as err: line = err.partial
		except asyncio.LimitOverrunError:
			line = await stream.read(self.line_max_len)
			while True:
				try: await stream.readuntil(sep)
				except asyncio.IncompleteReadError: break
				except asyncio.LimitOverrunError: await stream.read(self.line_max_len)
				else: break

		line = line.decode(decode_enc, decode_err)
		if len(line) > crop_to: line = line[:crop_to] + crop_mark
		return line


	def print_progress_prefix(self, msg):
		prefix_max_len = self.term_width - len(msg)
		if prefix_max_len >= len(self.prefix) + 10:
			prefix_len, prefix = prefix_max_len - len(self.prefix) - 6, repr(self.src)
			if len(prefix) > prefix_len: prefix = prefix[:prefix_len]
			prefix = ' '.join(filter(None, [f'[{prefix}]', self.prefix]))
			msg = f'{prefix}: {msg}'
		elif prefix_max_len > 3: msg = '{}: {}'.format(self.prefix[:prefix_max_len-2], msg)
		else: msg = msg[:self.term_width]
		return msg

	async def print_progress(self):
		report, pos_str = dict(), lambda n:\
			'{:02d}:{:02d}:{:02d}'.format(*map(int, [n//3600, (n%3600)//60, n%60]))
		print_progress = ft.partial(self.progress_func, (self.src, self.prefix))
		try:
			while True:
				line = await self.readline()
				if not line: return
				k, v = line.split('=', 1)
				report[k] = v
				if k != 'progress': continue
				pos = int(report.get('out_time_ms', 0)) / 1000000
				if not pos: continue
				if not self.stream_len: msg = pos_str(pos)
				else:
					msg = '{:.1f}% - {} / {}'.format(
						min(1, pos / self.stream_len) * 100,
						pos_str(pos), pos_str(self.stream_len) )
				msg = self.print_progress_prefix(msg)
				print_progress(msg)
		finally: print_progress()


class YTDLProc(FFProc):

	prefix = 'ytdl'

	async def print_progress(self):
		print_progress = ft.partial(self.progress_func, (self.src, self.prefix))
		try:
			while True:
				line = await self.readline()
				if not line: return
				if not line.startswith('[download]'): continue
				msg = self.print_progress_prefix(f'{line[10:].strip()}')
				print_progress(msg)
		finally: print_progress()



class AudioConvError(Exception): pass

class AudioConvJob:
	__slots__ = 'name src dst input_opts tmp_file ffmpeg can_copy_stream'.split()
	def __init__(self, *args, **kws):
		for k,v in it.chain(zip(self.__slots__, args), kws.items()): setattr(self, k, v)


class AudioConvSubResult(Path): pass

class AudioConvProbed(AudioConvSubResult):

	def __new__(cls, path, cleanup=False, duration=None, codec=None, label=None):
		if isinstance(path, AudioConvProbed): return path
		self = super().__new__(cls, path)
		self.label = label or self.name
		self.cleanup, self.duration, self.codec = cleanup, duration, codec
		return self

	def _repr(self, ext=''):
		return ( f'<{self.__class__.__name__} {self.label!r}'
			f' [del={self.cleanup} d={self.duration} c={self.codec}{ext}]>' )
	def __repr__(self): return self._repr()

class AudioConvChunk(AudioConvProbed):

	def __new__(cls, path, dst, start, duration=None, codec=None, label=None):
		self = super().__new__(cls, str(path), False, duration, codec, label)
		self.dst, self.start = dst, start
		return self

	def _repr(self, ext=''): return super()._repr(f' ss={self.start}')

class AudioConvChunkDir(Path):

	def __new__(cls, path, src, chunks, cleanup=False):
		self = super().__new__(cls, path)
		self.src, self.chunks, self.cleanup = src, chunks, cleanup
		return self



class AudioConv:

	@classmethod
	async def run_async(cls, *args, **kws):
		async with cls(*args, **kws) as self: return await self.run()

	def __init__(self, loop, src_list,
			start=None, length=None, chunks=None,
			probe=None, inplace=False, remove_src=False,
			loudnorm=False, loudnorm_opts=None, ytdl_opts=None, max_parallel=None ):
		self.loop, self.src_list, self.max_parallel = loop, src_list, max_parallel or os.cpu_count()
		self.start, self.length, self.chunks, self.probe = start, length, chunks, probe
		self.inplace, self.remove_src = inplace, remove_src
		self.loudnorm, self.loudnorm_opts = loudnorm, loudnorm_opts or ''
		self.ytdl_opts = ytdl_opts or list()
		self.status_lines, self.chunk_dirs = dict(), set()

	async def __aenter__(self):
		self.conv_jobs, self.status_line_task = OrderedDict(), None
		self.success, self.src_done, self.exit_sig = False, OrderedDict(), None
		return self

	async def __aexit__(self, *err):
		if self.conv_jobs:
			await self.conv_cleanup()
		if self.status_line_task:
			self.status_line_task.cancel()
			await self.status_line_task
			self.status_line_task = None
		if self.chunk_dirs:
			for p in self.chunk_dirs:
				chunks_done = self.src_done.get(p.src, set())
				if chunks_done != p.chunks:
					for c in chunks_done:
						with contextlib.suppress(OSError): c.unlink()
				with contextlib.suppress(OSError): p.rmdir()
				if p.cleanup:
					with contextlib.suppress(OSError): p.src.unlink()
			self.chunk_dirs.clear()

	async def run(self):
		self.conv = self.loop.create_task(self.conv_list())
		self.status_line_task = self.loop.create_task(self.status_line_cycle())
		def sig_handler(sig):
			self.exit_sig = sig
			self.conv.cancel()
		for sig in 'int', 'term':
			self.loop.add_signal_handler(
				getattr(signal, f'SIG{sig.upper()}'), ft.partial(sig_handler, sig) )
		with contextlib.suppress(asyncio.CancelledError): await self.conv
		return self.success


	async def status_line_cycle(self, interval=1.0):
		status_queue, term_width = list(), shutil.get_terminal_size()[0] - 2
		term_pad = lambda line: (
			(line + ' '*max(0, term_width - len(line)))\
				if len(line) < term_width else line[:term_width] )
		while True:
			if self.status_lines:
				if not status_queue: status_queue.extend(sorted(self.status_lines))
				k = status_queue.pop()
				try: line, end = self.status_lines[k], ''
				except KeyError: continue
				if line.endswith('\n'): # final status for this key
					line, end = line.rstrip('\n'), '\n'
					del self.status_lines[k]
				print('\r' + term_pad(line), end=end, flush=True)
			try: await asyncio.sleep(interval)
			except asyncio.CancelledError:
				for k in it.chain(status_queue, list(self.status_lines)):
					line = self.status_lines.pop(k, None)
					if line: print('\r' + term_pad(line.rstrip('\n')), end='\n', flush=True)
				break

	def status_line_set(self, key, line=None):
		if line: self.status_lines[key] = line
		elif key in self.status_lines: self.status_lines[key] += '\n'


	async def conv_cleanup(self, *task_ids, raise_errors=False):
		if not task_ids: task_ids = list(self.conv_jobs.keys())
		for task_id in task_ids:
			conv = self.conv_jobs.pop(task_id)
			conv.cancel()
			try: await conv
			except asyncio.CancelledError: pass
			except Exception as err:
				log.exception('conv-job crashed during cleanup: [{}] {}', *err_with_type(err))
				if raise_errors: raise

	async def conv_list(self):
		src_stack = list(reversed(self.src_list))
		while True:
			# Processing sequence:
			#  str or Path
			#  if str (ytdl url): [ -(conv_ytdl)-> AudioConvSubResult ]
			#  -(conv_probe)-> AudioConvProbed
			#  if chunks: [ -> N x AudioConvChunk ]
			#  -(conv_src)-> dst
			# All AudioConvSubResult types are Path subclasses with metadata.

			while src_stack and len(self.conv_jobs) < self.max_parallel:
				src = src_stack.pop()
				start, length = self.start, self.length

				if not isinstance(src, Path):
					conv = self.conv_ytdl(src, self.ytdl_opts)
				elif not isinstance(src, AudioConvProbed):
					conv = self.conv_probe(src, self.start, self.length)
				elif self.probe:
					print(f'{src.label} [{src.codec}] :: {naturaltime_diff(src.duration)}')
					conv = None
				elif self.chunks and not isinstance(src, AudioConvChunk):
					if not src.duration:
						raise AudioConvError( 'Cannot split src'
							f' into chunks due to unknown duration: {src}' )
					src_chunks, chunk_len, dst_name = list(), self.chunks, src.name.rsplit('.', 1)[0]
					start, length = start or 0, src.duration
					length_total = length - start
					dst_dir = ( dst_name if not self.inplace
						else (str(src.parent.resolve()).strip(os.sep) + f'/{dst_name}') )
					dst_dir = AudioConvChunkDir(dst_dir, src, src_chunks, cleanup=src.cleanup)
					dst_dir.mkdir(parents=True, exist_ok=True)
					while length > 0:
						n = len(src_chunks) + 1
						dst_file = f'{n:03d}__{dst_name}.ogg'
						src_chunks.append(AudioConvChunk(
							src, dst_dir / dst_file, start, min(chunk_len, length), src.codec, dst_file ))
						start += chunk_len; length -= chunk_len
					dst_dir.chunks = set(Path(c.dst) for c in dst_dir.chunks)
					self.chunk_dirs.add(dst_dir)
					src_stack.extend(reversed(src_chunks))
					print( f'Splitting {src.label!r}: {len(src_chunks)} chunks'
						f' ({naturaltime_diff(chunk_len)} each), {naturaltime_diff(length_total)} total' )
					continue
				else:
					if isinstance(src, AudioConvChunk):
						dst, start, length = src.dst, src.start, src.duration
					else:
						dst_base = src.name.rsplit('.', 1)[0]
						if self.inplace: dst_base = str(src.parent.resolve()).strip(os.sep) + f'/{dst_base}'
						dst = Path(dst_base + '.ogg')
						if dst.resolve() == src.resolve():
							for n in it.chain([''], range(2**30)):
								dst = Path(f'{dst_base}.copy{n}.ogg')
								if not dst.exists(): break
							else: raise AudioConvError(f'Failed to generate copy-path for dst: {dst}')
						dst.parent.mkdir(parents=True, exist_ok=True)
					conv = self.conv_src(src, dst, start, length)

				if conv:
					log.debug('Scheduling new conv-job for src: {}', src)
					conv = self.loop.create_task(conv)
					conv.src, conv.task_id = src, id(conv)
					self.conv_jobs[conv.task_id] = conv
			if not self.conv_jobs: break

			done, pending = await asyncio.wait(
				self.conv_jobs.values(), return_when=asyncio.FIRST_COMPLETED )
			for res in done:
				dst_path = await res
				dst_sub = isinstance(dst_path, AudioConvSubResult)
				log.debug( 'conv-job done (sub={},'
					' dst-file={!r}) for src: {!r}', int(dst_sub), dst_path, src )
				await self.conv_cleanup(res.task_id, raise_errors=True)
				if dst_sub: src_stack.append(dst_path)
				else: self.src_done.setdefault(res.src, set()).add(Path(dst_path))

		if not self.probe:
			assert len(self.src_done) == len(self.src_list)
			assert all((self.src_done[p.src] == p.chunks) for p in self.chunk_dirs)

		if self.remove_src:
			for src, dst_set in self.src_done.items():
				if len(dst_set) == 1:
					dst = list(dst_set)[0]
					if dst.resolve() == src.resolve(): src = None
					elif ( self.inplace
							and dst.parent.resolve() == src.parent.resolve()
							and src.name.lower().endswith('.ogg') ):
						os.rename(dst, src) # special case for .copyX.ogg files in the same dir
						src = None
				if src: os.unlink(src)

		self.success = True


	conv_ytdl_name_len_max = 100

	def conv_ytdl_fix_name(self, name, len_max, len_slug=20):
		if len(name) <= len_max: return name
		name, ext = name.rsplit('.', 1) if '.' in name else (name, None)
		if len(ext) >= len_slug: name, ext = f'{name}.{ext}', None
		name_list = name.split()
		for n, slug in sorted(enumerate(name_list), key=lambda v: -len(v[1])):
			if len(slug) > len_slug: name_list[n] = slug[:len_slug-3] + '---'
			else: break
		name = ' '.join(name_list)
		if len(name) > len_max: name = name[:len_max]
		if ext: name = f'{name}.{ext}'
		assert len(name) < len_max + len_slug, [len(name), name]
		return name

	async def conv_ytdl(self, url, ytdl_opts=None):
		if not ytdl_opts:
			# Preference should be for something with vorbis-encoded audio,
			#  but audio-only downloads are very slow for whatever reason (caching? throttling?)
			ytdl_opts = ['-f', '43/18/480p/bestaudio[ext=ogg]/bestaudio[ext=webm]/bestaudio/best']
		ytdl_opts = ['youtube-dl', '--newline'] + ytdl_opts
		async with YTDLProc( self.loop, url,
				ytdl_opts + ['--get-filename', url],
				stdout=subprocess.PIPE ) as proc:
			src = (await proc.stdout.read()).strip().decode()
			await proc.finished
		if not src or '\n' in src:
			raise AudioConvError(f'Weird output from "youtube-dl --get-filename": {src!r}')
		src = Path(src)
		if len(src.name) > self.conv_ytdl_name_len_max:
			src = src.parent / self.conv_ytdl_fix_name(src.name, self.conv_ytdl_name_len_max)
		src_part = Path(src.parent) / f'{src.name}.part'
		ytdl_opts.extend(['-o', str(src).replace('%', '%%')])
		try:
			async with YTDLProc( self.loop, src.name,
					ytdl_opts + [url], progress_func=self.status_line_set ) as proc:
				await proc.finished
		finally:
			with contextlib.suppress(OSError): src_part.unlink()
		return AudioConvSubResult(src)


	async def conv_probe(self, src, start=None, length=None):
		src_name, src_cleanup = src.name, isinstance(src, AudioConvSubResult)
		async with FFProc( self.loop, src_name,
				[ 'ffprobe', '-v', 'fatal', '-show_entries',
					'stream=codec_type,codec_name,duration:format=duration',
					'-print_format', 'json', str(src) ],
				stdout=subprocess.PIPE ) as proc:
			src_info = (await proc.stdout.read()).decode()
			await proc.finished
			src_duration = src_codec = None
			try:
				src_info = json.loads(src_info)
				for stream in src_info['streams']:
					if stream.get('codec_type') != 'audio': continue
					src_duration = float(stream.get('duration', 0))
					src_codec = stream.get('codec_name')
					break
				if not src_duration:
					src_duration = float(src_info['format']['duration'])
			except Exception as err:
				log.error( '[{!r}] ffprobe failed, progress'
					' info wont be available: [{}] {}', src_name, *err_with_type(err) )
			if src_duration:
				if start: src_duration = max(0, src_duration - start)
				if length: src_duration = min(src_duration, length)
			log.debug('[{!r}] Detected audio stream duration: {:.1f}s', src_name, src_duration)
			log.debug('[{!r}] Detected audio stream codec: {!r}', src_name, src_codec)
		return AudioConvProbed(src, src_cleanup, src_duration, src_codec)


	async def conv_src(self, src, dst, start=None, length=None):
		paths = {dst}
		src = AudioConvProbed(src)
		if src.cleanup: paths.add(src)

		def tmp_file(ext):
			p = f'{dst}.{ext}'
			paths.add(p)
			return p

		job_input_opts = list()
		if start: job_input_opts.extend(['-ss', str(start)])
		if length: job_input_opts.extend(['-t', str(length)])
		job = AudioConvJob(src.label, src, dst, job_input_opts, tmp_file)

		ffmpeg_cmd = 'ffmpeg -v error -hide_banner -y -progress pipe:1'.split()
		job.ffmpeg = lambda pre, cmd_ext, **kws: FFProc(
			self.loop, job.name, ffmpeg_cmd + cmd_ext, stream_len=src.duration,
			prefix=pre, progress_func=self.status_line_set, **kws )
		job.can_copy_stream = src.codec == 'vorbis'

		func = self.conv_src_simple if not self.loudnorm else self.conv_src_loudnorm
		try:
			await func(job)
			paths.remove(dst)
		finally:
			for p in paths:
				with contextlib.suppress(OSError): os.unlink(p)
		return dst


	async def conv_src_simple(self, job):
		coding_opts = ['-vn']
		if job.can_copy_stream: coding_opts += ['-c:a', 'copy']
		await job.ffmpeg( 'to-ogg', ['-i', str(job.src)]
			+ job.input_opts + coding_opts + ['-f', 'ogg', str(job.dst)] ).run()

	async def conv_src_loudnorm(self, job):
		await job.ffmpeg( 'to-wav [1/3]',
			['-i', str(job.src)] + job.input_opts + ['-f', 'wav', job.tmp_file('src.wav')] ).run()

		ffmpeg_env = os.environ.copy()
		ffmpeg_env['NO_COLOR'] = '1'
		opts = self.loudnorm_opts.strip(':')
		if opts: opts += ':'

		async with job.ffmpeg( 'loudnorm-info [2/3]',
				[ '-v', 'info', '-i', job.tmp_file('src.wav'),
					'-af', f'loudnorm={opts}print_format=json', '-f', 'null', '/dev/null' ],
				env=ffmpeg_env, stderr=subprocess.PIPE ) as proc:
			norm_info, ffmpeg_stderr = list(), list()
			while True:
				line = await proc.readline('stderr')
				ffmpeg_stderr.append(line.rstrip())
				if not line: break
				line = line.strip()
				if norm_info:
					assert not line.endswith(proc.crop_mark)
					norm_info.append(line)
					if line == '}': break
				if re.search(r'^\[Parsed_loudnorm_0 @ 0x[0-f]+\]$', line): norm_info.append('')
			norm_info = ''.join(norm_info)
			try: await proc.finished
			except:
				log.error(
					'ffmpeg stderr:\n--------------------\n{}\n--------------------',
					'\n'.join(ffmpeg_stderr).rstrip() )
				raise
			log.debug('[{!r}] detected audio normalization info: {!r}', job.name, norm_info)
			if not norm_info:
				raise AudioConvError( 'ffmpeg failed to produce'
					f' normalization info json (source file: {job.name!r})' )
			norm_info = json.loads(norm_info)
			with open(job.tmp_file('loudnorm.json'), 'w') as dst:
				json.dump(norm_info, dst, sort_keys=True, indent=2, separators=(',', ': '))

		opts_ext = (
				'measured_I={}:measured_TP={}:'
				'measured_LRA={}:measured_thresh={}:offset={}'
			).format(*op.itemgetter(
				'input_i', 'input_tp', 'input_lra', 'input_thresh', 'target_offset' )(norm_info))
		await job.ffmpeg( 'to-ogg [3/3]', [ '-i', job.tmp_file('src.wav'), '-af',
				f'loudnorm={opts}{opts_ext}', '-ar', '48k', '-f', 'ogg', str(job.dst) ]).run()


def parse_pos_spec(pos):
	if not pos: return
	try: mins, secs = pos.rsplit(':', 1)
	except ValueError: hrs, mins, secs = 0, 0, pos
	else:
		try: hrs, mins = mins.rsplit(':', 1)
		except ValueError: hrs = 0
	return sum( a*b for a, b in
		zip([3600, 60, 1], map(float, [hrs, mins, secs])) )

def main(args=None):
	import argparse
	parser = argparse.ArgumentParser(
		description='Convert source file(s) to audio, normalize it and encode to ogg/vorbis.'
			' Optionally uses ffmpeg "loudnorm" filter: https://ffmpeg.org/ffmpeg-all.html#loudnorm')

	group = parser.add_argument_group('Source/destination')
	group.add_argument('src', nargs='+',
		help='File(s) or URL(s) to convert.'
			' Files that both dont exist and have ":" in the name'
				' will be treated as URLs (to be processed with youtube-dl first).')
	group.add_argument('-x', '--remove-src', action='store_true',
		help='Remove source file(s) on success of the whole operation.')
	group.add_argument('-i', '--inplace', action='store_true',
		help='Recursively (following symlinks) replace source files'
				' with .ogg ones in the same dir(s) where they are found.'
			' All "src" args must be paths.'
			' Does not imply --remove-src (creates copies next to src files), unless specified.')
	group.add_argument('-t', '--dst-dir', metavar='path',
		help='Path to store resulting files in. Defaults to current one (unless --inplace).'
			' With --inplace also specified, full dst realpath will be re-created under this dir.')
	group.add_argument('-y', '--ytdl-opts',
		action='append', metavar='opts',
		help='Extra opts for youtube-dl command.'
			' Will determine the name for resulting file from youtube-dl -o option.'
			' Default is to override -f option for suitable audio formats,'
				' but leave -o unspecified (i.e. use default or config file).'
			' Will be split on spaces, unless option is used multiple times.')

	group = parser.add_argument_group('Volume normalization')
	group.add_argument('-n', '--loudnorm', action='store_true',
		help='Use ffmpeg "loudnorm" filter to have sane volume level.'
			' It takes quite a while to process longer files with it.'
			' Should not be available in pre-3.1 (2016-06-27) ffmpeg builds.'
			' ffmpeg docs link: https://ffmpeg.org/ffmpeg-all.html#loudnorm')
	group.add_argument('-o', '--loudnorm-opts', metavar='ffmpeg-af-opts',
		help='String of options to pass to loudnorm filter,'
				' same as they would appear on ffmpeg command line.'
			' Example: I=-16:TP=-1.5:LRA=11')

	group = parser.add_argument_group('Other ffmpeg options')
	group.add_argument('-s', '--start', metavar='((hh:)mm:)ss(.ms)',
		help='Convert only part of src file(s), starting from specified timestamp.'
			' Passed to ffmpeg -ss option, see "Time duration" in ffmpeg-utils(1) manpage.')
	group.add_argument('-l', '--length', metavar='((hh:)mm:)ss(.ms)',
		help='Convert only specified length of src file(s). Can be combined with -s/--start.'
			' Passed to ffmpeg -t option, see "Time duration" in ffmpeg-utils(1) manpage.')
	group.add_argument('-c', '--chunks',
		nargs='?', metavar='((hh:)mm:)ss(.ms)', const='15:00',
		help='Create dst directory instead of file with'
				' output pre-split into chunks of specified length.'
			' Can be used for enable faster parallel encoding.'
			' Length argument is optional and defaults to 15:00 (15 min).')

	group = parser.add_argument_group('Debug/misc')
	group.add_argument('-j', '--max-parallel', type=int,
		help='Max number of processing jobs to run in parallel.'
			' Default or 0 will be set to number of available cpu threads.')
	group.add_argument('-p', '--probe', action='store_true',
		help='Only probe and print length for each file, without converting anything.')
	group.add_argument('-d', '--debug', action='store_true', help='Verbose operation mode.')

	opts = parser.parse_args(sys.argv[1:] if args is None else args)

	src_list = list(
		(Path(src).resolve() if os.path.exists(src) or ':' not in src else src)
		for src in opts.src )

	if opts.inplace:
		src_list, src_list_old = list(), src_list
		for p in src_list_old:
			if not isinstance(p, Path):
				parser.error(f'Source arg is not a path (with --inplace specified): {p}')
			if p.is_dir():
				for root, dirs, files, dir_fd in os.fwalk(p, follow_symlinks=True):
					root = Path(root)
					for p in files: src_list.append(root / p)
		os.chdir(opts.dst_dir or '/')
	elif opts.dst_dir: os.chdir(opts.dst_dir)
	start, length, chunks = map(parse_pos_spec, [opts.start, opts.length, opts.chunks])

	ytdl_opts = opts.ytdl_opts or list()
	if len(ytdl_opts) == 1: ytdl_opts = ytdl_opts[0].strip().split()

	global log
	logging.basicConfig(level=logging.DEBUG if opts.debug else logging.WARNING)
	log = get_logger('main')

	if opts.loudnorm:
		import subprocess, distutils.version
		ffmpeg_info = subprocess.run(['ffmpeg', '-version'], stdout=subprocess.PIPE, check=True)
		ffmpeg_ver = check = None
		for line in ffmpeg_info.stdout.decode().splitlines():
			if line.startswith('ffmpeg version'):
				ffmpeg_ver = distutils.version.LooseVersion(line.split()[2])
				if ffmpeg_ver >= '3.2.0': check = True
				elif ffmpeg_ver < '3.1.0': check = False
				else: continue
				break
			if ffmpeg_ver and line.startswith('configuration:'):
				assert ffmpeg_ver >= '3.1.0' and ffmpeg_ver < '3.1.999', ffmpeg_ver
				check = '--enable-libebur128' in line.split()
				break
		if check is False:
			parser.error('--loudnorm option is used, but libebur128 support in ffmpeg is not detected')
		elif check is None:
			log.warning( 'Failed to conclusively check ffmpeg (detected version: {})'
				' for libebur128 support, script can fail at volume normalization steps', ffmpeg_ver )

	with contextlib.closing(asyncio.get_event_loop()) as loop:
		success = loop.run_until_complete(
			AudioConv.run_async(
				loop, src_list, start=start, length=length, chunks=chunks,
				max_parallel=opts.max_parallel, probe=opts.probe, inplace=opts.inplace,
				remove_src=opts.remove_src, ytdl_opts=ytdl_opts,
				loudnorm=opts.loudnorm, loudnorm_opts=opts.loudnorm_opts ) )

	return int(not success)

if __name__ == '__main__': sys.exit(main())
